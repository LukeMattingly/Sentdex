{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train = True, download=True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(\"\", train = False, download = True, \n",
    "                     transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset  = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 7, 6, 5, 0, 3, 5, 3, 5, 5])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#plt.imshow(data[0][0])\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e35eda4cc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0 , 5:0 ,6:0 , 7:0, 8:0 , 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] +=1\n",
    "        total+=1\n",
    "        \n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two libraries are interchangeable, nn is object oriented, and functional allow us just to pass parameters. \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.fc1 = nn.Linear(784, 64) #Input:784 is 28*28, from the flattened image, 64 hidden connected neurons\n",
    "        self.fc2 = nn.Linear(64, 64) #Input: has to input 64, since the output from the first layer was 64\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) #Output 10 neurons for the 10 classes of the MNIST\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) #defining data flow        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        #you can throw logic into this feed forward, like an if statement do this section, else do another. \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1) #dim 1 is similar to axis, what do we want so that the probably dist can sum to 1. \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6804e-01, 2.7455e-02, 2.9987e-01, 2.7195e-01, 5.3070e-01, 3.7842e-01,\n",
       "         1.6335e-02, 1.9211e-01, 6.8206e-01, 7.8282e-01, 3.7915e-01, 7.2305e-01,\n",
       "         5.8096e-01, 9.9658e-01, 9.7552e-01, 1.8648e-01, 1.3642e-01, 8.9671e-01,\n",
       "         1.5576e-01, 8.8126e-01, 5.3524e-01, 1.7380e-01, 2.2085e-01, 7.7626e-01,\n",
       "         8.5268e-01, 1.7933e-01, 9.4559e-01, 1.1181e-01, 9.0027e-01, 7.3760e-01,\n",
       "         6.9511e-01, 3.3395e-01, 6.4719e-01, 3.5619e-02, 4.5965e-01, 1.3811e-01,\n",
       "         6.7771e-01, 4.7827e-01, 1.4586e-01, 1.6454e-01, 6.4517e-01, 9.9606e-01,\n",
       "         2.1842e-01, 3.9828e-01, 5.9989e-01, 8.5978e-01, 4.4493e-01, 3.5752e-01,\n",
       "         4.3054e-01, 3.9462e-01, 5.7315e-01, 3.9278e-01, 6.6776e-01, 3.8333e-01,\n",
       "         4.5423e-01, 7.2273e-01, 3.5285e-01, 1.1680e-01, 1.5460e-02, 2.8444e-01,\n",
       "         4.4087e-01, 3.7739e-01, 7.7771e-01, 8.9361e-01, 9.4929e-02, 5.3396e-01,\n",
       "         7.3679e-01, 2.5298e-01, 2.8253e-01, 9.4502e-01, 6.7527e-01, 2.9530e-02,\n",
       "         5.2219e-02, 3.5876e-01, 9.5159e-02, 9.3132e-01, 6.0688e-02, 5.5231e-01,\n",
       "         1.5478e-01, 8.5878e-01, 7.8962e-01, 5.0932e-01, 3.3277e-01, 6.3989e-01,\n",
       "         8.5043e-01, 7.5414e-01, 2.3057e-01, 7.3375e-01, 8.1817e-02, 1.0601e-01,\n",
       "         9.9892e-01, 5.0042e-01, 7.5691e-01, 9.4928e-01, 1.5923e-01, 5.5642e-01,\n",
       "         6.9746e-01, 6.4930e-01, 5.7878e-01, 9.9560e-01, 4.6703e-01, 8.2592e-01,\n",
       "         3.5804e-01, 2.6987e-01, 5.1564e-01, 8.8897e-01, 2.8269e-01, 2.9946e-01,\n",
       "         7.4662e-01, 1.3728e-01, 3.4897e-01, 8.1494e-01, 5.2843e-01, 9.5607e-01,\n",
       "         8.7727e-01, 2.9380e-01, 7.6006e-01, 2.6729e-01, 3.7137e-01, 2.2938e-01,\n",
       "         8.3419e-01, 1.4815e-01, 3.7928e-01, 4.6464e-01, 5.2898e-01, 1.4289e-01,\n",
       "         8.4815e-01, 8.4516e-01, 8.1238e-03, 2.4799e-01, 6.1053e-01, 5.6851e-01,\n",
       "         9.3301e-01, 6.5529e-01, 1.2661e-01, 9.6765e-02, 3.7793e-01, 3.4863e-01,\n",
       "         5.1041e-01, 1.1936e-01, 3.0009e-01, 3.3504e-01, 9.0520e-02, 9.2503e-01,\n",
       "         4.5244e-01, 9.6381e-01, 6.6767e-01, 3.6324e-01, 1.7660e-01, 5.4374e-01,\n",
       "         1.8717e-01, 6.1024e-02, 7.4411e-01, 3.7838e-01, 1.9718e-01, 9.3278e-01,\n",
       "         7.6655e-01, 3.3713e-01, 5.9995e-02, 5.6101e-01, 3.0682e-01, 1.2745e-01,\n",
       "         2.1965e-01, 3.2910e-01, 3.1934e-01, 9.0228e-02, 7.7816e-01, 4.7555e-01,\n",
       "         2.2300e-01, 4.1951e-01, 8.9271e-01, 2.1347e-01, 7.2585e-01, 8.1519e-01,\n",
       "         4.2139e-01, 6.5180e-01, 6.6087e-01, 3.5674e-01, 5.4831e-01, 7.6887e-01,\n",
       "         8.1858e-01, 5.2915e-01, 4.6940e-01, 6.5023e-01, 3.7096e-01, 9.7268e-01,\n",
       "         3.6013e-01, 6.2642e-02, 4.4391e-01, 3.9072e-01, 3.1719e-01, 1.2405e-01,\n",
       "         8.4864e-01, 4.2429e-01, 8.4705e-02, 3.7436e-01, 3.6624e-01, 5.4799e-01,\n",
       "         5.3395e-01, 9.1870e-01, 9.9633e-01, 4.6715e-02, 7.2408e-01, 5.7274e-01,\n",
       "         9.1819e-01, 2.9734e-01, 8.8675e-01, 8.0823e-01, 2.3255e-01, 4.0251e-01,\n",
       "         7.7290e-01, 9.7050e-01, 8.8629e-01, 9.5868e-01, 9.6751e-01, 5.3692e-01,\n",
       "         4.9768e-01, 4.0216e-01, 3.8980e-01, 3.5018e-01, 3.6466e-01, 1.4787e-01,\n",
       "         4.9410e-01, 4.3885e-01, 7.8431e-02, 1.7504e-01, 3.0679e-01, 9.7200e-02,\n",
       "         2.5587e-01, 7.9355e-01, 1.8456e-01, 5.6602e-01, 5.9323e-01, 7.4233e-01,\n",
       "         6.9759e-01, 9.6799e-01, 5.0238e-03, 5.1208e-02, 2.8684e-01, 4.3326e-01,\n",
       "         4.4444e-01, 3.3562e-01, 8.1646e-01, 2.0390e-01, 4.7775e-01, 6.6714e-01,\n",
       "         8.3435e-01, 4.4726e-01, 9.5607e-01, 4.3722e-01, 8.6236e-02, 7.4562e-01,\n",
       "         5.4713e-01, 3.4404e-01, 3.8002e-01, 8.4984e-01, 9.5087e-01, 9.4416e-01,\n",
       "         3.9174e-02, 5.5182e-01, 7.9397e-01, 1.4707e-01, 6.3609e-01, 5.6659e-01,\n",
       "         3.6304e-01, 7.0073e-01, 5.9627e-02, 6.7332e-01, 5.8020e-01, 1.5181e-01,\n",
       "         4.1855e-01, 7.2197e-01, 6.9341e-01, 4.8604e-02, 3.2885e-01, 4.2659e-01,\n",
       "         1.0396e-01, 5.6198e-02, 5.4340e-01, 6.7863e-01, 1.4329e-01, 7.9875e-01,\n",
       "         7.4350e-01, 4.9053e-01, 5.8475e-01, 8.2139e-01, 8.1152e-01, 2.8127e-01,\n",
       "         6.9859e-01, 6.8505e-01, 1.6919e-01, 4.9544e-01, 1.1589e-01, 6.0744e-02,\n",
       "         3.6993e-01, 2.6569e-01, 9.9622e-01, 9.9996e-01, 1.6207e-01, 9.9350e-01,\n",
       "         4.1964e-01, 8.8733e-01, 3.9453e-01, 8.3306e-01, 8.5316e-01, 1.5184e-01,\n",
       "         2.6529e-01, 7.8946e-01, 8.9841e-01, 6.8676e-02, 8.2514e-01, 3.4327e-01,\n",
       "         8.5353e-02, 4.2313e-01, 1.8306e-01, 5.3831e-01, 2.5549e-01, 8.8881e-01,\n",
       "         7.2047e-01, 8.6364e-01, 8.5878e-01, 1.7866e-01, 2.8563e-01, 1.3845e-01,\n",
       "         4.0638e-01, 3.3962e-01, 1.7360e-01, 9.1228e-01, 2.9640e-01, 7.0921e-01,\n",
       "         6.6397e-01, 6.4423e-01, 1.0261e-01, 2.0735e-01, 2.8048e-02, 7.0660e-01,\n",
       "         7.0286e-01, 2.2014e-02, 5.8264e-01, 8.0640e-01, 2.0206e-01, 2.1415e-01,\n",
       "         5.7539e-01, 4.6847e-01, 8.7957e-01, 1.8007e-02, 1.4183e-01, 5.9995e-02,\n",
       "         2.0299e-01, 5.2387e-01, 4.0441e-01, 1.6807e-01, 9.5862e-01, 7.3896e-01,\n",
       "         6.0006e-01, 9.1553e-01, 9.2664e-01, 7.0894e-01, 6.0182e-01, 6.4300e-01,\n",
       "         4.7208e-01, 5.4801e-04, 1.0708e-01, 5.1579e-01, 4.4815e-01, 1.3214e-01,\n",
       "         2.6144e-01, 4.4806e-01, 9.4985e-01, 9.6260e-01, 7.2393e-01, 8.1888e-01,\n",
       "         1.1523e-01, 1.2870e-01, 6.9008e-01, 6.8463e-01, 4.2745e-01, 6.2290e-01,\n",
       "         6.8591e-01, 1.3385e-01, 6.8254e-01, 9.2699e-01, 2.4245e-01, 6.5611e-01,\n",
       "         7.8564e-01, 6.8512e-01, 2.4446e-01, 6.3744e-01, 9.0030e-01, 8.7473e-01,\n",
       "         7.1926e-01, 3.1925e-01, 4.3669e-01, 1.6051e-01, 1.3187e-01, 3.6600e-01,\n",
       "         7.5585e-01, 8.3633e-01, 6.4515e-01, 6.6375e-02, 5.3344e-01, 1.9687e-01,\n",
       "         1.2943e-01, 8.1539e-01, 8.0613e-01, 8.5867e-01, 8.6047e-01, 5.7986e-02,\n",
       "         2.6349e-01, 2.6097e-01, 9.6836e-01, 4.6266e-01, 8.3558e-01, 8.1900e-01,\n",
       "         1.1402e-01, 4.6788e-01, 8.0385e-01, 7.5476e-01, 5.7459e-01, 9.2889e-01,\n",
       "         2.8168e-01, 9.6296e-01, 2.3236e-01, 6.1193e-01, 9.5200e-01, 6.6365e-01,\n",
       "         3.5108e-02, 9.7117e-01, 8.8974e-01, 4.1226e-01, 6.5488e-01, 1.4922e-01,\n",
       "         4.8697e-01, 7.4694e-01, 1.7815e-01, 9.5007e-01, 8.9008e-01, 5.9705e-01,\n",
       "         8.5446e-01, 8.8827e-01, 6.4331e-01, 9.7536e-01, 7.6731e-02, 5.2451e-01,\n",
       "         3.4801e-01, 1.7621e-01, 9.5368e-02, 7.8780e-01, 1.6897e-01, 7.5826e-01,\n",
       "         1.2239e-01, 8.1021e-01, 4.0653e-02, 3.3268e-01, 4.7941e-01, 2.9013e-01,\n",
       "         4.5279e-01, 7.7825e-01, 3.8264e-01, 2.7799e-01, 9.6886e-01, 3.0646e-01,\n",
       "         6.2199e-01, 4.3564e-01, 6.8932e-01, 9.4527e-01, 5.3264e-01, 4.5880e-01,\n",
       "         2.6955e-01, 7.5233e-02, 1.6388e-01, 3.9203e-01, 5.4406e-01, 9.9559e-01,\n",
       "         7.8425e-01, 8.5212e-01, 9.8157e-01, 3.3096e-01, 8.3249e-01, 5.2557e-01,\n",
       "         1.1435e-01, 4.1990e-01, 3.7279e-01, 3.5736e-01, 9.5525e-01, 2.5261e-02,\n",
       "         8.0908e-01, 2.3773e-02, 1.9211e-01, 3.0296e-01, 2.5211e-02, 3.8228e-01,\n",
       "         3.8643e-02, 3.4666e-01, 8.9769e-01, 7.4104e-02, 7.5433e-01, 3.6279e-01,\n",
       "         7.2947e-01, 7.3967e-01, 7.4801e-01, 4.4221e-01, 8.0450e-01, 7.2485e-01,\n",
       "         3.5556e-01, 6.7645e-01, 1.1196e-01, 3.2561e-01, 1.3464e-01, 1.4376e-01,\n",
       "         7.7580e-01, 9.2282e-01, 4.0073e-01, 1.3983e-01, 2.3178e-01, 7.2133e-01,\n",
       "         1.1870e-01, 5.7284e-01, 3.5141e-01, 5.3052e-01, 2.8678e-01, 9.3164e-01,\n",
       "         1.0418e-01, 5.0251e-02, 7.0164e-01, 8.2069e-01, 9.9129e-01, 7.9418e-01,\n",
       "         2.2714e-01, 6.7951e-01, 1.2672e-01, 9.9750e-01, 7.0353e-01, 2.2428e-01,\n",
       "         3.3330e-01, 2.8412e-01, 4.0038e-01, 3.8346e-01, 4.6694e-01, 2.1818e-01,\n",
       "         8.8704e-01, 3.9661e-01, 8.8375e-01, 1.9499e-01, 3.2216e-01, 5.9112e-02,\n",
       "         2.6688e-01, 3.5655e-01, 3.8534e-01, 1.0383e-01, 1.6946e-01, 8.9276e-01,\n",
       "         4.3386e-01, 5.8006e-01, 3.4339e-01, 3.6382e-01, 7.3433e-05, 5.2791e-01,\n",
       "         4.2222e-01, 7.5624e-01, 9.2296e-01, 1.1492e-01, 9.2735e-01, 1.7831e-01,\n",
       "         1.5886e-01, 1.7598e-01, 5.9866e-01, 1.5776e-01, 4.9070e-01, 9.5328e-02,\n",
       "         2.4660e-01, 6.3539e-01, 2.7817e-01, 3.9401e-01, 5.5919e-01, 3.2090e-01,\n",
       "         1.6430e-01, 7.1159e-01, 1.7311e-01, 4.0023e-01, 1.9299e-01, 4.9918e-01,\n",
       "         1.1088e-01, 1.5759e-01, 6.3033e-01, 9.1613e-01, 3.5735e-01, 7.0823e-01,\n",
       "         9.9960e-01, 1.5106e-01, 6.5289e-01, 2.9630e-01, 9.6262e-01, 7.8754e-02,\n",
       "         3.9274e-01, 2.2269e-01, 1.8979e-01, 8.6090e-01, 1.8605e-01, 4.8416e-01,\n",
       "         1.1425e-01, 4.6978e-01, 5.3020e-01, 2.7269e-01, 7.9298e-01, 8.5523e-01,\n",
       "         1.8840e-02, 5.7066e-01, 9.5694e-01, 2.0227e-01, 9.7641e-01, 3.4959e-01,\n",
       "         9.6683e-01, 8.0639e-01, 6.5745e-01, 8.4351e-01, 6.3825e-01, 8.1639e-01,\n",
       "         3.5349e-01, 4.2990e-01, 6.8039e-01, 5.0935e-01, 7.5303e-01, 7.8316e-01,\n",
       "         1.8322e-01, 8.4345e-01, 7.2982e-01, 2.4285e-01, 8.9099e-03, 4.7345e-01,\n",
       "         3.7533e-01, 9.5551e-02, 6.4912e-01, 7.9282e-01, 5.6159e-01, 1.7724e-01,\n",
       "         3.6301e-01, 5.6883e-01, 9.5130e-01, 6.3510e-01, 3.0791e-01, 5.7283e-01,\n",
       "         4.0540e-01, 2.6647e-01, 9.9862e-01, 3.4961e-01, 1.4736e-01, 8.6634e-01,\n",
       "         3.5442e-01, 3.2195e-01, 9.4199e-01, 3.4188e-01, 2.4259e-01, 6.0726e-01,\n",
       "         7.1550e-01, 1.9162e-01, 7.7551e-01, 1.4473e-01, 4.3327e-01, 9.2028e-01,\n",
       "         5.6275e-02, 1.1515e-01, 2.1717e-01, 6.9231e-01, 9.0666e-01, 1.6949e-01,\n",
       "         7.8146e-01, 4.8809e-01, 3.8589e-01, 3.1746e-01, 2.8713e-01, 2.3724e-01,\n",
       "         6.4465e-01, 8.1791e-01, 8.9542e-01, 4.2971e-01, 1.5293e-01, 1.0106e-01,\n",
       "         4.6376e-01, 6.4315e-01, 7.2505e-01, 3.9813e-01, 8.1789e-01, 7.5118e-01,\n",
       "         9.8328e-01, 2.5993e-01, 5.5896e-01, 5.6211e-01, 5.5494e-02, 8.9190e-01,\n",
       "         7.0943e-01, 5.7978e-01, 6.1314e-01, 2.2007e-01, 2.1484e-01, 9.7452e-01,\n",
       "         5.6659e-01, 4.9251e-01, 3.8046e-01, 4.1460e-01, 7.6590e-01, 3.1536e-01,\n",
       "         1.0981e-01, 7.0807e-01, 8.9079e-02, 7.2720e-01, 4.9810e-01, 3.0014e-01,\n",
       "         1.4292e-01, 9.8192e-01, 5.7810e-01, 5.4679e-01, 9.9919e-02, 3.0473e-01,\n",
       "         7.6827e-01, 9.5609e-01, 2.0501e-02, 7.6767e-01, 3.0865e-01, 3.0191e-02,\n",
       "         1.2969e-01, 2.5499e-01, 5.6420e-01, 4.8602e-02, 7.1947e-01, 2.0212e-01,\n",
       "         3.0082e-01, 6.0804e-01, 6.5501e-01, 3.6517e-01, 1.1235e-01, 2.3046e-01,\n",
       "         6.7015e-01, 2.9416e-01, 2.2916e-01, 8.6755e-01, 6.6394e-01, 9.9041e-01,\n",
       "         3.5497e-02, 2.1852e-01, 8.0982e-01, 5.4359e-02, 8.6063e-01, 4.8418e-01,\n",
       "         8.9277e-01, 4.0873e-01, 6.4100e-01, 5.1886e-01, 5.5868e-01, 9.6987e-01,\n",
       "         6.1121e-01, 4.1235e-01, 6.2670e-01, 2.0940e-01, 2.6460e-01, 4.0564e-01,\n",
       "         3.6329e-01, 1.5212e-01, 1.5016e-01, 9.0466e-01, 5.4248e-01, 9.5417e-01,\n",
       "         8.9570e-01, 1.6729e-01, 7.2371e-01, 2.3335e-01, 3.8021e-02, 5.2491e-01,\n",
       "         7.8562e-01, 2.5610e-01, 3.1693e-01, 1.3410e-01, 6.1148e-02, 2.1081e-01,\n",
       "         1.0593e-01, 3.5812e-01, 3.8510e-01, 6.9171e-01, 3.6517e-01, 5.7301e-01,\n",
       "         5.1023e-01, 1.7593e-01, 2.0237e-01, 5.4637e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1872, -2.2687, -2.3193, -2.2558, -2.3686, -2.2176, -2.4028, -2.4037,\n",
       "         -2.2875, -2.3399]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0513, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2178, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001) #learning rate using adam optimizer\n",
    "\n",
    "EPOCHS = 3 #full passes through our data\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset: #data is a batch of featuresets and labels\n",
    "        X,y = data\n",
    "        net.zero_grad() #using batches for the gradient\n",
    "        output = net(X.view(-1, 784))\n",
    "        loss = F.nll_loss(output, y) #calculate the loss, how wrong were we with our pred\n",
    "        #one hot vector is [0,1,0, 0] where only one of the values in the vector is 'hot' or 'on', we could use MSE if you have a vector rather than a scalar\n",
    "        loss.backward() #this provides us with the back prop alg\n",
    "        optimizer.step() #this adjusts the weights for us\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.961\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total +=1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.976\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total +=1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[4].view(28,28))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[4].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
