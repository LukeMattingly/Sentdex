{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train = True, download=True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(\"\", train = False, download = True, \n",
    "                     transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset  = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 7, 6, 5, 0, 3, 5, 3, 5, 5])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#plt.imshow(data[0][0])\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e35eda4cc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0 , 5:0 ,6:0 , 7:0, 8:0 , 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] +=1\n",
    "        total+=1\n",
    "        \n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two libraries are interchangeable, nn is object oriented, and functional allow us just to pass parameters. \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.fc1 = nn.Linear(784, 64) #Input:784 is 28*28, from the flattened image, 64 hidden connected neurons\n",
    "        self.fc2 = nn.Linear(64, 64) #Input: has to input 64, since the output from the first layer was 64\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) #Output 10 neurons for the 10 classes of the MNIST\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) #defining data flow        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        #you can throw logic into this feed forward, like an if statement do this section, else do another. \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1) #dim 1 is similar to axis, what do we want so that the probably dist can sum to 1. \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6804e-01, 2.7455e-02, 2.9987e-01, 2.7195e-01, 5.3070e-01, 3.7842e-01,\n",
       "         1.6335e-02, 1.9211e-01, 6.8206e-01, 7.8282e-01, 3.7915e-01, 7.2305e-01,\n",
       "         5.8096e-01, 9.9658e-01, 9.7552e-01, 1.8648e-01, 1.3642e-01, 8.9671e-01,\n",
       "         1.5576e-01, 8.8126e-01, 5.3524e-01, 1.7380e-01, 2.2085e-01, 7.7626e-01,\n",
       "         8.5268e-01, 1.7933e-01, 9.4559e-01, 1.1181e-01, 9.0027e-01, 7.3760e-01,\n",
       "         6.9511e-01, 3.3395e-01, 6.4719e-01, 3.5619e-02, 4.5965e-01, 1.3811e-01,\n",
       "         6.7771e-01, 4.7827e-01, 1.4586e-01, 1.6454e-01, 6.4517e-01, 9.9606e-01,\n",
       "         2.1842e-01, 3.9828e-01, 5.9989e-01, 8.5978e-01, 4.4493e-01, 3.5752e-01,\n",
       "         4.3054e-01, 3.9462e-01, 5.7315e-01, 3.9278e-01, 6.6776e-01, 3.8333e-01,\n",
       "         4.5423e-01, 7.2273e-01, 3.5285e-01, 1.1680e-01, 1.5460e-02, 2.8444e-01,\n",
       "         4.4087e-01, 3.7739e-01, 7.7771e-01, 8.9361e-01, 9.4929e-02, 5.3396e-01,\n",
       "         7.3679e-01, 2.5298e-01, 2.8253e-01, 9.4502e-01, 6.7527e-01, 2.9530e-02,\n",
       "         5.2219e-02, 3.5876e-01, 9.5159e-02, 9.3132e-01, 6.0688e-02, 5.5231e-01,\n",
       "         1.5478e-01, 8.5878e-01, 7.8962e-01, 5.0932e-01, 3.3277e-01, 6.3989e-01,\n",
       "         8.5043e-01, 7.5414e-01, 2.3057e-01, 7.3375e-01, 8.1817e-02, 1.0601e-01,\n",
       "         9.9892e-01, 5.0042e-01, 7.5691e-01, 9.4928e-01, 1.5923e-01, 5.5642e-01,\n",
       "         6.9746e-01, 6.4930e-01, 5.7878e-01, 9.9560e-01, 4.6703e-01, 8.2592e-01,\n",
       "         3.5804e-01, 2.6987e-01, 5.1564e-01, 8.8897e-01, 2.8269e-01, 2.9946e-01,\n",
       "         7.4662e-01, 1.3728e-01, 3.4897e-01, 8.1494e-01, 5.2843e-01, 9.5607e-01,\n",
       "         8.7727e-01, 2.9380e-01, 7.6006e-01, 2.6729e-01, 3.7137e-01, 2.2938e-01,\n",
       "         8.3419e-01, 1.4815e-01, 3.7928e-01, 4.6464e-01, 5.2898e-01, 1.4289e-01,\n",
       "         8.4815e-01, 8.4516e-01, 8.1238e-03, 2.4799e-01, 6.1053e-01, 5.6851e-01,\n",
       "         9.3301e-01, 6.5529e-01, 1.2661e-01, 9.6765e-02, 3.7793e-01, 3.4863e-01,\n",
       "         5.1041e-01, 1.1936e-01, 3.0009e-01, 3.3504e-01, 9.0520e-02, 9.2503e-01,\n",
       "         4.5244e-01, 9.6381e-01, 6.6767e-01, 3.6324e-01, 1.7660e-01, 5.4374e-01,\n",
       "         1.8717e-01, 6.1024e-02, 7.4411e-01, 3.7838e-01, 1.9718e-01, 9.3278e-01,\n",
       "         7.6655e-01, 3.3713e-01, 5.9995e-02, 5.6101e-01, 3.0682e-01, 1.2745e-01,\n",
       "         2.1965e-01, 3.2910e-01, 3.1934e-01, 9.0228e-02, 7.7816e-01, 4.7555e-01,\n",
       "         2.2300e-01, 4.1951e-01, 8.9271e-01, 2.1347e-01, 7.2585e-01, 8.1519e-01,\n",
       "         4.2139e-01, 6.5180e-01, 6.6087e-01, 3.5674e-01, 5.4831e-01, 7.6887e-01,\n",
       "         8.1858e-01, 5.2915e-01, 4.6940e-01, 6.5023e-01, 3.7096e-01, 9.7268e-01,\n",
       "         3.6013e-01, 6.2642e-02, 4.4391e-01, 3.9072e-01, 3.1719e-01, 1.2405e-01,\n",
       "         8.4864e-01, 4.2429e-01, 8.4705e-02, 3.7436e-01, 3.6624e-01, 5.4799e-01,\n",
       "         5.3395e-01, 9.1870e-01, 9.9633e-01, 4.6715e-02, 7.2408e-01, 5.7274e-01,\n",
       "         9.1819e-01, 2.9734e-01, 8.8675e-01, 8.0823e-01, 2.3255e-01, 4.0251e-01,\n",
       "         7.7290e-01, 9.7050e-01, 8.8629e-01, 9.5868e-01, 9.6751e-01, 5.3692e-01,\n",
       "         4.9768e-01, 4.0216e-01, 3.8980e-01, 3.5018e-01, 3.6466e-01, 1.4787e-01,\n",
       "         4.9410e-01, 4.3885e-01, 7.8431e-02, 1.7504e-01, 3.0679e-01, 9.7200e-02,\n",
       "         2.5587e-01, 7.9355e-01, 1.8456e-01, 5.6602e-01, 5.9323e-01, 7.4233e-01,\n",
       "         6.9759e-01, 9.6799e-01, 5.0238e-03, 5.1208e-02, 2.8684e-01, 4.3326e-01,\n",
       "         4.4444e-01, 3.3562e-01, 8.1646e-01, 2.0390e-01, 4.7775e-01, 6.6714e-01,\n",
       "         8.3435e-01, 4.4726e-01, 9.5607e-01, 4.3722e-01, 8.6236e-02, 7.4562e-01,\n",
       "         5.4713e-01, 3.4404e-01, 3.8002e-01, 8.4984e-01, 9.5087e-01, 9.4416e-01,\n",
       "         3.9174e-02, 5.5182e-01, 7.9397e-01, 1.4707e-01, 6.3609e-01, 5.6659e-01,\n",
       "         3.6304e-01, 7.0073e-01, 5.9627e-02, 6.7332e-01, 5.8020e-01, 1.5181e-01,\n",
       "         4.1855e-01, 7.2197e-01, 6.9341e-01, 4.8604e-02, 3.2885e-01, 4.2659e-01,\n",
       "         1.0396e-01, 5.6198e-02, 5.4340e-01, 6.7863e-01, 1.4329e-01, 7.9875e-01,\n",
       "         7.4350e-01, 4.9053e-01, 5.8475e-01, 8.2139e-01, 8.1152e-01, 2.8127e-01,\n",
       "         6.9859e-01, 6.8505e-01, 1.6919e-01, 4.9544e-01, 1.1589e-01, 6.0744e-02,\n",
       "         3.6993e-01, 2.6569e-01, 9.9622e-01, 9.9996e-01, 1.6207e-01, 9.9350e-01,\n",
       "         4.1964e-01, 8.8733e-01, 3.9453e-01, 8.3306e-01, 8.5316e-01, 1.5184e-01,\n",
       "         2.6529e-01, 7.8946e-01, 8.9841e-01, 6.8676e-02, 8.2514e-01, 3.4327e-01,\n",
       "         8.5353e-02, 4.2313e-01, 1.8306e-01, 5.3831e-01, 2.5549e-01, 8.8881e-01,\n",
       "         7.2047e-01, 8.6364e-01, 8.5878e-01, 1.7866e-01, 2.8563e-01, 1.3845e-01,\n",
       "         4.0638e-01, 3.3962e-01, 1.7360e-01, 9.1228e-01, 2.9640e-01, 7.0921e-01,\n",
       "         6.6397e-01, 6.4423e-01, 1.0261e-01, 2.0735e-01, 2.8048e-02, 7.0660e-01,\n",
       "         7.0286e-01, 2.2014e-02, 5.8264e-01, 8.0640e-01, 2.0206e-01, 2.1415e-01,\n",
       "         5.7539e-01, 4.6847e-01, 8.7957e-01, 1.8007e-02, 1.4183e-01, 5.9995e-02,\n",
       "         2.0299e-01, 5.2387e-01, 4.0441e-01, 1.6807e-01, 9.5862e-01, 7.3896e-01,\n",
       "         6.0006e-01, 9.1553e-01, 9.2664e-01, 7.0894e-01, 6.0182e-01, 6.4300e-01,\n",
       "         4.7208e-01, 5.4801e-04, 1.0708e-01, 5.1579e-01, 4.4815e-01, 1.3214e-01,\n",
       "         2.6144e-01, 4.4806e-01, 9.4985e-01, 9.6260e-01, 7.2393e-01, 8.1888e-01,\n",
       "         1.1523e-01, 1.2870e-01, 6.9008e-01, 6.8463e-01, 4.2745e-01, 6.2290e-01,\n",
       "         6.8591e-01, 1.3385e-01, 6.8254e-01, 9.2699e-01, 2.4245e-01, 6.5611e-01,\n",
       "         7.8564e-01, 6.8512e-01, 2.4446e-01, 6.3744e-01, 9.0030e-01, 8.7473e-01,\n",
       "         7.1926e-01, 3.1925e-01, 4.3669e-01, 1.6051e-01, 1.3187e-01, 3.6600e-01,\n",
       "         7.5585e-01, 8.3633e-01, 6.4515e-01, 6.6375e-02, 5.3344e-01, 1.9687e-01,\n",
       "         1.2943e-01, 8.1539e-01, 8.0613e-01, 8.5867e-01, 8.6047e-01, 5.7986e-02,\n",
       "         2.6349e-01, 2.6097e-01, 9.6836e-01, 4.6266e-01, 8.3558e-01, 8.1900e-01,\n",
       "         1.1402e-01, 4.6788e-01, 8.0385e-01, 7.5476e-01, 5.7459e-01, 9.2889e-01,\n",
       "         2.8168e-01, 9.6296e-01, 2.3236e-01, 6.1193e-01, 9.5200e-01, 6.6365e-01,\n",
       "         3.5108e-02, 9.7117e-01, 8.8974e-01, 4.1226e-01, 6.5488e-01, 1.4922e-01,\n",
       "         4.8697e-01, 7.4694e-01, 1.7815e-01, 9.5007e-01, 8.9008e-01, 5.9705e-01,\n",
       "         8.5446e-01, 8.8827e-01, 6.4331e-01, 9.7536e-01, 7.6731e-02, 5.2451e-01,\n",
       "         3.4801e-01, 1.7621e-01, 9.5368e-02, 7.8780e-01, 1.6897e-01, 7.5826e-01,\n",
       "         1.2239e-01, 8.1021e-01, 4.0653e-02, 3.3268e-01, 4.7941e-01, 2.9013e-01,\n",
       "         4.5279e-01, 7.7825e-01, 3.8264e-01, 2.7799e-01, 9.6886e-01, 3.0646e-01,\n",
       "         6.2199e-01, 4.3564e-01, 6.8932e-01, 9.4527e-01, 5.3264e-01, 4.5880e-01,\n",
       "         2.6955e-01, 7.5233e-02, 1.6388e-01, 3.9203e-01, 5.4406e-01, 9.9559e-01,\n",
       "         7.8425e-01, 8.5212e-01, 9.8157e-01, 3.3096e-01, 8.3249e-01, 5.2557e-01,\n",
       "         1.1435e-01, 4.1990e-01, 3.7279e-01, 3.5736e-01, 9.5525e-01, 2.5261e-02,\n",
       "         8.0908e-01, 2.3773e-02, 1.9211e-01, 3.0296e-01, 2.5211e-02, 3.8228e-01,\n",
       "         3.8643e-02, 3.4666e-01, 8.9769e-01, 7.4104e-02, 7.5433e-01, 3.6279e-01,\n",
       "         7.2947e-01, 7.3967e-01, 7.4801e-01, 4.4221e-01, 8.0450e-01, 7.2485e-01,\n",
       "         3.5556e-01, 6.7645e-01, 1.1196e-01, 3.2561e-01, 1.3464e-01, 1.4376e-01,\n",
       "         7.7580e-01, 9.2282e-01, 4.0073e-01, 1.3983e-01, 2.3178e-01, 7.2133e-01,\n",
       "         1.1870e-01, 5.7284e-01, 3.5141e-01, 5.3052e-01, 2.8678e-01, 9.3164e-01,\n",
       "         1.0418e-01, 5.0251e-02, 7.0164e-01, 8.2069e-01, 9.9129e-01, 7.9418e-01,\n",
       "         2.2714e-01, 6.7951e-01, 1.2672e-01, 9.9750e-01, 7.0353e-01, 2.2428e-01,\n",
       "         3.3330e-01, 2.8412e-01, 4.0038e-01, 3.8346e-01, 4.6694e-01, 2.1818e-01,\n",
       "         8.8704e-01, 3.9661e-01, 8.8375e-01, 1.9499e-01, 3.2216e-01, 5.9112e-02,\n",
       "         2.6688e-01, 3.5655e-01, 3.8534e-01, 1.0383e-01, 1.6946e-01, 8.9276e-01,\n",
       "         4.3386e-01, 5.8006e-01, 3.4339e-01, 3.6382e-01, 7.3433e-05, 5.2791e-01,\n",
       "         4.2222e-01, 7.5624e-01, 9.2296e-01, 1.1492e-01, 9.2735e-01, 1.7831e-01,\n",
       "         1.5886e-01, 1.7598e-01, 5.9866e-01, 1.5776e-01, 4.9070e-01, 9.5328e-02,\n",
       "         2.4660e-01, 6.3539e-01, 2.7817e-01, 3.9401e-01, 5.5919e-01, 3.2090e-01,\n",
       "         1.6430e-01, 7.1159e-01, 1.7311e-01, 4.0023e-01, 1.9299e-01, 4.9918e-01,\n",
       "         1.1088e-01, 1.5759e-01, 6.3033e-01, 9.1613e-01, 3.5735e-01, 7.0823e-01,\n",
       "         9.9960e-01, 1.5106e-01, 6.5289e-01, 2.9630e-01, 9.6262e-01, 7.8754e-02,\n",
       "         3.9274e-01, 2.2269e-01, 1.8979e-01, 8.6090e-01, 1.8605e-01, 4.8416e-01,\n",
       "         1.1425e-01, 4.6978e-01, 5.3020e-01, 2.7269e-01, 7.9298e-01, 8.5523e-01,\n",
       "         1.8840e-02, 5.7066e-01, 9.5694e-01, 2.0227e-01, 9.7641e-01, 3.4959e-01,\n",
       "         9.6683e-01, 8.0639e-01, 6.5745e-01, 8.4351e-01, 6.3825e-01, 8.1639e-01,\n",
       "         3.5349e-01, 4.2990e-01, 6.8039e-01, 5.0935e-01, 7.5303e-01, 7.8316e-01,\n",
       "         1.8322e-01, 8.4345e-01, 7.2982e-01, 2.4285e-01, 8.9099e-03, 4.7345e-01,\n",
       "         3.7533e-01, 9.5551e-02, 6.4912e-01, 7.9282e-01, 5.6159e-01, 1.7724e-01,\n",
       "         3.6301e-01, 5.6883e-01, 9.5130e-01, 6.3510e-01, 3.0791e-01, 5.7283e-01,\n",
       "         4.0540e-01, 2.6647e-01, 9.9862e-01, 3.4961e-01, 1.4736e-01, 8.6634e-01,\n",
       "         3.5442e-01, 3.2195e-01, 9.4199e-01, 3.4188e-01, 2.4259e-01, 6.0726e-01,\n",
       "         7.1550e-01, 1.9162e-01, 7.7551e-01, 1.4473e-01, 4.3327e-01, 9.2028e-01,\n",
       "         5.6275e-02, 1.1515e-01, 2.1717e-01, 6.9231e-01, 9.0666e-01, 1.6949e-01,\n",
       "         7.8146e-01, 4.8809e-01, 3.8589e-01, 3.1746e-01, 2.8713e-01, 2.3724e-01,\n",
       "         6.4465e-01, 8.1791e-01, 8.9542e-01, 4.2971e-01, 1.5293e-01, 1.0106e-01,\n",
       "         4.6376e-01, 6.4315e-01, 7.2505e-01, 3.9813e-01, 8.1789e-01, 7.5118e-01,\n",
       "         9.8328e-01, 2.5993e-01, 5.5896e-01, 5.6211e-01, 5.5494e-02, 8.9190e-01,\n",
       "         7.0943e-01, 5.7978e-01, 6.1314e-01, 2.2007e-01, 2.1484e-01, 9.7452e-01,\n",
       "         5.6659e-01, 4.9251e-01, 3.8046e-01, 4.1460e-01, 7.6590e-01, 3.1536e-01,\n",
       "         1.0981e-01, 7.0807e-01, 8.9079e-02, 7.2720e-01, 4.9810e-01, 3.0014e-01,\n",
       "         1.4292e-01, 9.8192e-01, 5.7810e-01, 5.4679e-01, 9.9919e-02, 3.0473e-01,\n",
       "         7.6827e-01, 9.5609e-01, 2.0501e-02, 7.6767e-01, 3.0865e-01, 3.0191e-02,\n",
       "         1.2969e-01, 2.5499e-01, 5.6420e-01, 4.8602e-02, 7.1947e-01, 2.0212e-01,\n",
       "         3.0082e-01, 6.0804e-01, 6.5501e-01, 3.6517e-01, 1.1235e-01, 2.3046e-01,\n",
       "         6.7015e-01, 2.9416e-01, 2.2916e-01, 8.6755e-01, 6.6394e-01, 9.9041e-01,\n",
       "         3.5497e-02, 2.1852e-01, 8.0982e-01, 5.4359e-02, 8.6063e-01, 4.8418e-01,\n",
       "         8.9277e-01, 4.0873e-01, 6.4100e-01, 5.1886e-01, 5.5868e-01, 9.6987e-01,\n",
       "         6.1121e-01, 4.1235e-01, 6.2670e-01, 2.0940e-01, 2.6460e-01, 4.0564e-01,\n",
       "         3.6329e-01, 1.5212e-01, 1.5016e-01, 9.0466e-01, 5.4248e-01, 9.5417e-01,\n",
       "         8.9570e-01, 1.6729e-01, 7.2371e-01, 2.3335e-01, 3.8021e-02, 5.2491e-01,\n",
       "         7.8562e-01, 2.5610e-01, 3.1693e-01, 1.3410e-01, 6.1148e-02, 2.1081e-01,\n",
       "         1.0593e-01, 3.5812e-01, 3.8510e-01, 6.9171e-01, 3.6517e-01, 5.7301e-01,\n",
       "         5.1023e-01, 1.7593e-01, 2.0237e-01, 5.4637e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1872, -2.2687, -2.3193, -2.2558, -2.3686, -2.2176, -2.4028, -2.4037,\n",
       "         -2.2875, -2.3399]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
